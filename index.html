<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>GraspDiff: Imitation Learning for Dual-Jaw Grippers</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      max-width: 800px;
      line-height: 1.6;
      background-color: #f9f9f9;
      color: #333;
    }
    h1, h2, h3 {
      color: #2c3e50;
    }
    code {
      background: #eee;
      padding: 2px 4px;
      border-radius: 4px;
    }
    .image-container {
      text-align: center;
      margin: 30px 0;
    }
    img {
      max-width: 100%;
      height: auto;
      border: 1px solid #ccc;
    }
    .button {
      display: inline-block;
      padding: 10px 15px;
      margin: 10px 0;
      background-color: #007acc;
      color: white;
      text-decoration: none;
      border-radius: 5px;
    }
    .button:hover {
      background-color: #005b99;
    }
  </style>
</head>
<body>

  <h1>GraspDiff</h1>
  <h3>Diffusion Policy for Dual-Jaw Robotic Grasping</h3>

  <p><strong>GraspDiff</strong> is a robotics research project that explores <b>imitation learning</b> using a <b>diffusion policy</b> to control a <b>UR10e robotic arm</b> equipped with a customized <b>two-DOF gripper</b>. This system learns to manipulate real-world objects‚Äîin this case, chickens‚Äîby mimicking human demonstrations.</p>

  <div class="image-container">
    <img src="demo.gif" alt="Robot demo">
    <p><i>Demonstration of the dual-jaw gripper learning to grasp and place objects.</i></p>
  </div>

  <h2>üöÄ Highlights</h2>
  <ul>
    <li>Uses <b>Diffusion Policy</b> for continuous action prediction</li>
    <li>Supports real-time control with a <b>SpaceMouse</b> interface</li>
    <li>Trained on real human demonstrations with a custom gripper</li>
    <li>Tested in industrial scenarios involving poultry handling</li>
  </ul>

  <h2>üß† Method</h2>
  <p>
    We leverage the power of <b>diffusion models</b> to learn a robust and flexible control policy from demonstrations. The dual-jaw gripper adds complexity in manipulation, and GraspDiff accounts for it by modeling an 8-dimensional action space: 6-DOF robot pose + 2-DOF gripper status.
  </p>

  <h2>üì¶ Repository Structure</h2>
  <ul>
    <li><code>gripper/</code> ‚Äì Custom hardware interface for jaw control</li>
    <li><code>scripts/</code> ‚Äì Real-time teleop and data collection</li>
    <li><code>policy/</code> ‚Äì Diffusion policy training and inference</li>
    <li><code>visualization/</code> ‚Äì Tools to visualize actions and trajectories</li>
  </ul>

  <h2>üìÑ Paper & Citation</h2>
  <p>
    Coming soon ‚Äî if you use this code, please cite our work!
  </p>

  <h2>üîó Links</h2>
  <ul>
    <li><a href="https://github.com/yourusername/GraspDiff" target="_blank">GitHub Repository</a></li>
    <li><a href="https://diffusion-policy.cs.columbia.edu" target="_blank">Diffusion Policy (original paper)</a></li>
  </ul>

  <p>
    <a class="button" href="https://github.com/yourusername/GraspDiff">View on GitHub</a>
  </p>

  <hr/>
  <p><small>¬© 2025 GraspDiff Project ‚Äì Built with ‚ù§Ô∏è by [Your Name or Lab]</small></p>

</body>
</html>
